{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "780d52767e1b5731",
   "metadata": {},
   "source": [
    "# Aprendizado Supervisionado no Neurônio Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as ferramentas\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score\n",
    "import math\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888a1c04",
   "metadata": {},
   "source": [
    "## Identificador da Equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b3403",
   "metadata": {},
   "source": [
    "O identificador trata-se de um código numérico de um dígito gerado pela soma do último dígito do número de matrícula de cada integrante do projeto em módulo 4. Este será usado em especificidades do presente projeto. Dessa forma, os números de matrículas são:\n",
    "\n",
    "* 2315080005\n",
    "* 2315080061\n",
    "* 2315080010\n",
    "* 2315080021\n",
    "* 2315080022\n",
    "\n",
    "Portanto, o identificador é dado por (5+1+0+1+2)mod(4) = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a23259",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "##  Parte I– Resolvendo um Problema Linearmente Separável\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "1. Usar o arquivo dataAll.txt\n",
    "2. Construir o algoritmo de treinamento do neurônio perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arq_input = \"dataAll.txt\"\n",
    "\n",
    "dataAll = np.fromfile(arq_input, dtype=np.float64)\n",
    "print(\"Tipo de dataAll: {}\".format(type(dataAll)))\n",
    "print(\"Número de elementos em dataAll: {}\".format(dataAll.size))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# -1 infers the size of the new dimension from the size of the input array.\n",
    "dataAll = np.reshape(dataAll, (1000, 1, 3))\n",
    "print(dataAll[:10]) # Mostrando 10 exemplos\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Shape de dataAll: {}\".format(dataAll.shape))\n",
    "print(\"Dimensões de dataAll: {}\".format(dataAll.ndim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Como havia 3000 exemplos anteriormente e agora a matriz tem dimensões (1, 3). \n",
    "Então, há 3000/3 = 1000 exemplos em dataAll. Ou seja, (1000, 1, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em x, y e rotulo \n",
    "\n",
    "print(\"x:\")\n",
    "x = dataAll[:, :, :2]\n",
    "print(x.shape)\n",
    "print(x[:10]) # Mostrando os 10 primeiros pontos \n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"y:\")\n",
    "y = dataAll[:,:, 2:]\n",
    "print(y.shape)\n",
    "print(y[:10]) # Rótulos dos pontos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Criando o neurônio Perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \"\"\"\n",
    "    A perceptron is a classification model that consists of a set of weights, or scores,\n",
    "    one for every feature, and a threshold. The perceptron multiplies each weight by its\n",
    "    corresponding score, and adds them, obtaining a score.\n",
    "    by Rajwrite Nath on Medium\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, threshold, lr, weight_low=-0.5, weight_high=0.5):\n",
    "        self.threshold = threshold\n",
    "        self.lr = lr\n",
    "        self.weights = None\n",
    "        self.weight_low = weight_low\n",
    "        self.weight_high = weight_high\n",
    "        self.scores = None\n",
    "        self.adjustments = 0\n",
    "        self.epochs = 0\n",
    "        self.bias = -1\n",
    "\n",
    "    def print_weights(self):\n",
    "        np.set_printoptions()\n",
    "        print(\"Weights:{}\".format(self.weights))\n",
    "\n",
    "    def gen_weights(self, low, high, size):\n",
    "        self.weights = np.random.uniform(low, high, size=size).reshape(-1, 1)\n",
    "\n",
    "    def step_fn(self, z):\n",
    "        return np.where(z >= self.threshold, 1, 0)\n",
    "\n",
    "    def error_fn(self, y_true, y_predicted):\n",
    "        return y_true - y_predicted\n",
    "\n",
    "    def predict(self, x_data):\n",
    "        return self.step_fn(np.dot(x_data, self.weights))\n",
    "\n",
    "    def fit(self, x_data, y_data):\n",
    "        \n",
    "        # Adicionando um bias ao x_data:\n",
    "        bias = np.full((x_data.shape[0], 1, 1), self.bias)\n",
    "        x_data = np.concatenate([bias, x_data], axis=2)\n",
    "        # print(x_data)\n",
    "        # print(x_data.shape)\n",
    "        \n",
    "        # Gerando pesos\n",
    "        self.gen_weights(self.weight_low, self.weight_high, size=x_data.shape[2])\n",
    "        # print(\"Início:\")\n",
    "        # self.print_weights()\n",
    "        # print(self.weights.shape)\n",
    "        \n",
    "        \n",
    "        y_predicted = self.predict(x_data)\n",
    "        self.scores = y_predicted  # Atualiza os scores\n",
    "\n",
    "        # Algoritmo executa até a convergência, supomos que as classes sejam linearmente separáveis\n",
    "        while not np.all(y_data == self.scores):\n",
    "\n",
    "            self.epochs += 1  # Não convergiu, vai necessitar de mais 1 época\n",
    "\n",
    "            # Para os pesos que resultaram em uma predição errada:\n",
    "\n",
    "            predicoes_incorretas = np.where(y_data != self.scores)[0]\n",
    "\n",
    "            for i in predicoes_incorretas:\n",
    "                x_i = x_data[i]\n",
    "                y_i = y_data[i]\n",
    "                y_pred = y_predicted[i]\n",
    "\n",
    "                # Calculando erros\n",
    "                error = self.error_fn(y_i, y_pred)\n",
    "\n",
    "                # Relculando pesos\n",
    "                self.weights += self.lr * error * x_i.T\n",
    "                self.adjustments += 1\n",
    "\n",
    "            y_predicted = self.predict(x_data)\n",
    "            self.scores = y_predicted # Atualiza os scores novamente com base nos ajustes\n",
    "\n",
    "# Inicializando o neurônio\n",
    "neuronio_perceptron = Perceptron(threshold=0, lr=0.1)\n",
    "neuronio_perceptron.fit(x, y)\n",
    "print(\"Final: \")\n",
    "neuronio_perceptron.print_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando o gráfico\n",
    "\n",
    "def gen_grafico(data, final_w, title):\n",
    "    x_1 = data[:,:, :1]\n",
    "    x_2 = data[:,:, 1:2]\n",
    "    y = data[:, :, 2:]\n",
    "    fig, ax = plt.subplots()\n",
    "    cor = {0: 'red', 1:'blue'}\n",
    "    for i in range(data.shape[0]):\n",
    "        plt.plot(x_1[i][0][0], x_2[i][0][0], marker='o', c = cor[y[i][0][0]])\n",
    "        \n",
    "    \n",
    "    x = np.arange(-1000, 1001, 1)\n",
    "    reta = (final_w[0][0]/final_w[2][0]) - (final_w[1][0]/final_w[2][0]) * x\n",
    "    plt.plot(x, reta, color='purple', linestyle='--', markersize=0.5)\n",
    "    ax.legend(cor, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax.grid(True)\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "gen_grafico(dataAll, neuronio_perceptron.weights, \"Distribução dos exemplos em dataAll\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Parte II - Experimentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "arq1 = \"data1.txt\"\n",
    "\n",
    "data1 = np.fromfile(arq1, dtype=np.float64)\n",
    "\n",
    "print(\"Tipo de data1: {}\".format(type(data1)))\n",
    "print(\"Número de elementos em data1: {}\".format(data1.size))\n",
    "print(\"\\n\")\n",
    "\n",
    "data1 = np.reshape(data1, (600, 1, 3))\n",
    "print(data1[:10])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Shape de data1: {}\".format(data1.shape))\n",
    "print(\"Dimensões de data1: {}\".format(data1.ndim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em x, y e rotulo \n",
    "\n",
    "print(\"x:\")\n",
    "x = data1[:, :, :2]\n",
    "print(x.shape)\n",
    "print(x[:10]) # Mostrando os 10 primeiros pontos \n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"y:\")\n",
    "y = data1[:,:, 2:]\n",
    "print(y.shape)\n",
    "print(y[:10]) # Rótulos dos pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [(0.4, (-100, 100)),\n",
    "         (0.1, (-100, 100)),\n",
    "         (0.01, (-100, 100)),\n",
    "         (0.4, (-0.5, 0.5)),\n",
    "         (0.1, (-0.5, 0.5)),\n",
    "         (0.01, (-0.5, 0.5))] # as seis configurações do \n",
    "\n",
    "def run_experiment(x, y, config, n_runs=10):\n",
    "    results = []\n",
    "    \n",
    "    for lr, (weight_low, weight_high) in config:\n",
    "        adjustments = []\n",
    "        epochs = []\n",
    "        \n",
    "        for _ in range (n_runs):\n",
    "            p = Perceptron(threshold=0, lr=lr, weight_low=weight_low, weight_high=weight_high)\n",
    "            p.fit(x, y)\n",
    "            adjustments.append(p.adjustments)\n",
    "            epochs.append(p.epochs)\n",
    "            \n",
    "        media_ajustes = np.mean(adjustments)\n",
    "        desvio_ajustes = np.std(adjustments)\n",
    "        menor_epoca = np.min(epochs)\n",
    "\n",
    "        results.append((lr, (weight_low, weight_high), media_ajustes, desvio_ajustes, menor_epoca))\n",
    "    \n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_table(results):\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Taxa de Aprendizado\", \"Intervalo de Pesos\", \"Quantidade de ajustes\", \"Menor número de épocas para convergência\"]\n",
    "\n",
    "    for lr, (w_low, w_high), media, desvio, min_epocas in results:\n",
    "        ajustes_fmt = f\"{media:.2f} ± {desvio:.2f}\"\n",
    "        intervalo_fmt = f\"({w_low}, {w_high})\"\n",
    "        table.add_row([lr, intervalo_fmt, ajustes_fmt, min_epocas])\n",
    "\n",
    "    print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_experiment(x, y, config, n_runs=10)\n",
    "print_results_table(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Taxas de aprendizado altas (0.1-0.4) aceleram a convergência (3-15 épocas) mas causam instabilidade, especialmente com pesos iniciais amplos (-100 a 100). Taxas baixas (0.01) são estáveis porém lentas (5-40 épocas), exceto quando combinadas com pesos em escala reduzida (-0.5 a 0.5), que otimizam o treinamento (1.400 ajustes em 5 épocas). A melhor configuração equilibrada é taxa 0.1 com pesos entre -0.5 e 0.5, garantindo convergência rápida (6 épocas) e estável. A escolha da inicialização e taxa de aprendizado é decisiva para um treinamento eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Parte III – Validação Holdout em Problema Não-Linearmente Separável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "arq_holdout = \"dataHoldout.txt\"\n",
    "\n",
    "dataHoldout = np.fromfile(arq_holdout, dtype=np.float64)\n",
    "\n",
    "print(\"Tipo de dataHoldout: {}\".format(type(dataHoldout)))\n",
    "print(\"Número de elementos em dataHoldout: {}\".format(dataHoldout.size))\n",
    "print(\"\\n\")\n",
    "\n",
    "dataHoldout = np.reshape(dataHoldout, (800, 1, 3))\n",
    "print(dataHoldout[:10])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Shape de dataHoldout: {}\".format(dataHoldout.shape))\n",
    "print(\"Dimensões de dataHoldout: {}\".format(dataHoldout.ndim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_grafico(data,title):\n",
    "    x_1 = data[:,:, :1]\n",
    "    x_2 = data[:,:, 1:2]\n",
    "    y = data[:, :, 2:]\n",
    "    fig, ax = plt.subplots()\n",
    "    cor = { 0: 'red', 1:'blue'}\n",
    "    for i in range(data.shape[0]):\n",
    "        plt.plot(x_1[i][0][0], x_2[i][0][0], marker='o', c = cor[y[i][0][0]])\n",
    "    \n",
    "    ax.legend(cor, loc='center left', bbox_to_anchor=(1, 0.5), labelcolor = [\"red\", \"blue\"])\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "        \n",
    "holdout_grafico(dataHoldout,\"Gráfico Inicial de Espalhamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declarando a semente de aleatoriedade\n",
    "np.random.seed(ID)\n",
    "\n",
    "#Utilização do permutation para embaralhar a array dataHoldout\n",
    "dataHoldout = np.random.permutation(dataHoldout)\n",
    "\n",
    "#Definição do tamanho do array de treino como 70% do original\n",
    "training_amount=int(800*0.7)\n",
    "\n",
    "#Divisão de teste e treino\n",
    "training_sample=dataHoldout[:(training_amount)]\n",
    "test_sample=dataHoldout[(training_amount):]\n",
    "\n",
    "#Análise se as amostras se mantém constantes \n",
    "print(training_sample[:10])\n",
    "print(\"\\n\")\n",
    "print(test_sample[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em x, y e rotulo de teste e treino\n",
    "\n",
    "print(\"x_Treino:\")\n",
    "x_training= training_sample[:, :, :2]\n",
    "print(x_training.shape)\n",
    "print(x_training[:5]) # Mostrando os 5 primeiros pontos \n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"y_training:\")\n",
    "y_training = training_sample[:,:, 2:]\n",
    "print(y_training.shape)\n",
    "print(y_training[:5]) # Rótulos dos pontos\n",
    "\n",
    "\n",
    "print(\"x_Teste:\")\n",
    "x_test= test_sample[:, :, :2]\n",
    "print(x_test.shape)\n",
    "print(x_test[:5]) # Mostrando os 5 primeiros pontos \n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"y_test:\")\n",
    "y_test = test_sample[:,:, 2:]\n",
    "print(y_test.shape)\n",
    "print(y_test[:5]) # Rótulos dos pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controled_Perceptron:\n",
    "    \"\"\"\n",
    "    This class works equals to the Perceptron class, but it doesn't stop when the neuron is all trained but when a\n",
    "    limit of epochs has been passed\n",
    " \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, threshold, lr ,limit):\n",
    "        self.threshold = threshold\n",
    "        self.lr = lr\n",
    "        self.weights = None\n",
    "        self.scores = None\n",
    "        self.adjustments = 0\n",
    "        self.epochs = 0\n",
    "        self.bias = -1\n",
    "        self.limit=limit\n",
    "\n",
    "    def print_weights(self):\n",
    "        np.set_printoptions()\n",
    "        print(\"Weights:{}\".format(self.weights))\n",
    "\n",
    "    def gen_weights(self, low, high, size):\n",
    "        self.weights = np.random.uniform(low, high, size=size).reshape(-1, 1)\n",
    "\n",
    "    def step_fn(self, z):\n",
    "        return np.where(z >= self.threshold, 1, 0)\n",
    "\n",
    "    def error_fn(self, y_true, y_predicted):\n",
    "        return y_true - y_predicted\n",
    "\n",
    "    def predict(self, x_data):\n",
    "        return self.step_fn(np.dot(x_data, self.weights))\n",
    "\n",
    "    def fit(self, x_data, y_data):\n",
    "        \n",
    "        # Adicionando um bias ao x_data:\n",
    "        bias = np.full((x_data.shape[0], 1, 1), self.bias)\n",
    "        x_data = np.concatenate([bias, x_data], axis=2)\n",
    "        print(x_data)\n",
    "        print(x_data.shape)\n",
    "        \n",
    "        # Gerando pesos\n",
    "        self.gen_weights(-0.5, 0.5, size=x_data.shape[2])\n",
    "        print(\"Início:\")\n",
    "        self.print_weights()\n",
    "        print(self.weights.shape)\n",
    "        \n",
    "        \n",
    "        y_predicted = self.predict(x_data)\n",
    "        self.scores = y_predicted  # Atualiza os scores\n",
    "\n",
    "        # Algoritmo executa até a convergência, supomos que as classes sejam linearmente separáveis\n",
    "        while(self.epochs<=self.limit):\n",
    "\n",
    "            self.epochs += 1  # Não convergiu, vai necessitar de mais 1 época\n",
    "\n",
    "            # Para os pesos que resultaram em uma predição errada:\n",
    "\n",
    "            predicoes_incorretas = np.where(y_data != self.scores)[0]\n",
    "\n",
    "            for i in predicoes_incorretas:\n",
    "                x_i = x_data[i]\n",
    "                y_i = y_data[i]\n",
    "                y_pred = y_predicted[i]\n",
    "\n",
    "                # Calculando erros\n",
    "                error = self.error_fn(y_i, y_pred)\n",
    "\n",
    "                # Relculando pesos\n",
    "                self.weights += self.lr * error * x_i.T\n",
    "                self.adjustments += 1\n",
    "\n",
    "            y_predicted = self.predict(x_data)\n",
    "            self.scores = y_predicted # Atualiza os scores novamente com base nos ajustes\n",
    "            \n",
    "neuronio_perceptron_holdout = Controled_Perceptron(threshold=0, lr=0.1, limit=100)\n",
    "neuronio_perceptron_holdout.fit(x_training, y_training)\n",
    "print(\"Final: \")\n",
    "neuronio_perceptron_holdout.print_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_line_grafico(data,final_w,title):\n",
    "    x_1 = data[:,:, :1]\n",
    "    x_2 = data[:,:, 1:2]\n",
    "    y = data[:, :, 2:]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    cor = { 0: 'red', 1:'blue'}\n",
    "    for i in range(data.shape[0]):\n",
    "        plt.plot(x_1[i][0][0], x_2[i][0][0], marker='o', c = cor[y[i][0][0]])\n",
    "        \n",
    "    x = np.arange(-1, 3, 1)\n",
    "    reta = (final_w[0][0]/final_w[2][0]) - (final_w[1][0]/final_w[2][0]) * x\n",
    "    plt.plot(x, reta, color='purple', linestyle='--', markersize=0.5)\n",
    "    \n",
    "    ax.legend(cor, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "        \n",
    "holdout_line_grafico(dataHoldout,neuronio_perceptron_holdout.weights,\"Distruibuição de exemplos de dataHoldout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a089d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(data, neuron):\n",
    "    bias = np.full((data.shape[0], 1, 1), neuron.bias)\n",
    "    data = np.concatenate([bias, data], axis=2)\n",
    "    return neuron.predict(data).reshape(-1)\n",
    "\n",
    "y_training_pred = pred(x_training, neuronio_perceptron_holdout)\n",
    "y_training = y_training.reshape(-1)\n",
    "\n",
    "y_test_pred = pred(x_test, neuronio_perceptron_holdout)\n",
    "y_test = y_test.reshape(-1)\n",
    "\n",
    "cm_training = confusion_matrix(y_training, y_training_pred, labels=[0, 1])\n",
    "cm_test = confusion_matrix(y_test, y_test_pred, labels=[0, 1])\n",
    "\n",
    "# Plotando\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "# Matriz de Treinamento\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_training, display_labels=[0,1]).plot(ax=ax[0], cmap=\"Reds\")\n",
    "ax[0].set_title(\"Matriz de Confusão - Treinamento\")\n",
    "\n",
    "# Matriz de Teste\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=[0,1]).plot(ax=ax[1], cmap=\"Blues\")\n",
    "ax[1].set_title(\"Matriz de Confusão - Teste\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422da402",
   "metadata": {},
   "source": [
    "Diante da matriz de confusão obtida, percebe-se um comportamento parecido tanto para os dados de treinamento quanto para os de teste. Errando apenas em alguns casos, tendo valores de falsos positivos e falsos negativos aproximados para essas quantidades de dados. No entanto, uma análise mais detalhada é possível apenas mediante o cálculo das métricas, o que será realizado em seguinda.\n",
    "\n",
    "Métricas a serem calculadas:\n",
    "1. Acurácia\n",
    "2. Precisão\n",
    "3. Revocação\n",
    "4. F-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3db3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metrics = {\n",
    "    \"accuracy\" : accuracy_score(y_training, y_training_pred),\n",
    "    \"precision\" : precision_score(y_training, y_training_pred, average=\"binary\"),\n",
    "    \"recall\" : recall_score(y_training, y_training_pred, average=\"binary\"),\n",
    "    \"f_1Score\" : f1_score(y_training, y_training_pred, average=\"binary\")\n",
    "    }\n",
    "\n",
    "test_metrics = {\n",
    "    \"accuracy\" : accuracy_score(y_test, y_test_pred),\n",
    "    \"precision\" : precision_score(y_test, y_test_pred, average=\"binary\"),\n",
    "    \"recall\" : recall_score(y_test, y_test_pred, average=\"binary\"),\n",
    "    \"f_1Score\" : f1_score(y_test, y_test_pred, average=\"binary\")\n",
    "    }\n",
    "\n",
    "table = PrettyTable()\n",
    "table.padding_width = 8\n",
    "\n",
    "table.title = \"Métricas de treinamento e de teste\"\n",
    "table.field_names = [\"\", \"Treinamento\", \"Teste\"]\n",
    "table.add_row([\"Acurácia\", f\"{training_metrics[\"accuracy\"]:.4f}\", f\"{test_metrics[\"accuracy\"]:.4f}\"])\n",
    "table.add_row([\"Precisão\", f\"{training_metrics[\"precision\"]:.4f}\", f\"{test_metrics[\"precision\"]:.4f}\"])\n",
    "table.add_row([\"Revocação\", f\"{training_metrics[\"recall\"]:.4f}\", f\"{test_metrics[\"recall\"]:.4f}\"])\n",
    "table.add_row([\"F1_Score\", f\"{training_metrics[\"f_1Score\"]:.4f}\", f\"{test_metrics[\"f_1Score\"]:.4f}\"])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(0.9138-0.9474/0.9474)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08f747f",
   "metadata": {},
   "source": [
    "As métricas utilizaram a média (average) binária, dado que a tarefa é de classificação binária desbalanceada. Diante disso, as métricas obtidas foram elevadas, i.e. acima de 90% em geral. A perda percentual da métrica F1_Score foi relativamente pequena, com um decréscimo de 8,62%. Tais métricas indicam uma boa convergência do modelo, apesar de este procurar uma solução linear para um problema não linear. Contudo, em se tratando da aplicabilidade do modelo, não é possível definí-lo como eficiente apenas com os dados obtidos. Isso se deve ao fato do número de dados utilizados ser reduzido, de modo que seja possível não estar refletindo precisamente os outliers, tornando a predição pouco eficaz para possíveis outros datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e280d980",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-1, 3, 1)\n",
    "\n",
    "w0, w1, w2 = neuronio_perceptron_holdout.weights\n",
    "w0, w1, w2 = w0[0], w1[0], w2[0]\n",
    "\n",
    "reta = (w0/w2) - (w1/w2) * x\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "ax[0].plot(x, reta, color='purple', linestyle='--', markersize=0.5)\n",
    "ax[1].plot(x, reta, color='purple', linestyle='--', markersize=0.5)\n",
    "\n",
    "cor = {0 : \"red\", 1 : \"blue\"}\n",
    "\n",
    "for i in range(x_training.shape[0]):\n",
    "    ax[0].plot(x_training[i][0][0], x_training[i][0][1], marker='o', c = cor[y_training[i]])\n",
    "ax[0].set_title(\"Distribuição de Dados para Treinamento\")\n",
    "\n",
    "for i in range(x_test.shape[0]):\n",
    "    ax[1].plot(x_test[i][0][0], x_test[i][0][1], marker='o', c = cor[y_test[i]])\n",
    "ax[1].set_title(\"Distribuição de Dados para Teste\")\n",
    "\n",
    "ax[1].legend((\"Função de ativação\", \"0\", \"1\"), loc='lower left', bbox_to_anchor=(1, 0), labelcolor=\"linecolor\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d873688",
   "metadata": {},
   "source": [
    "Com estes gráficos, é possível a visualização dos pontos dados como falsos positivos e falsos negativos na matriz de confusão, também é expressa a manutenção da proporção entre classes no processo de permutação do dataset durante o holdout."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

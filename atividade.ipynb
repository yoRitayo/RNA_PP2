{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Aprendizado Supervisionado no Neurônio Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as ferramentas\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "from sklearn import metrics\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "##  Parte I– Resolvendo um Problema Linearmente Separável\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "1. Usar o arquivo dataAll.txt\n",
    "2. Construir o algoritmo de treinamento do neurônio perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arq_input = \"dataAll.txt\"\n",
    "\n",
    "dataAll = np.fromfile(arq_input, dtype=np.float64)\n",
    "print(\"Tipo de dataAll: {}\".format(type(dataAll)))\n",
    "print(\"Número de elementos em dataAll: {}\".format(dataAll.size))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# -1 infers the size of the new dimension from the size of the input array.\n",
    "dataAll = np.reshape(dataAll, (1000, 1, 3))\n",
    "print(dataAll[:10]) # Mostrando 10 exemplos\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Shape de dataAll: {}\".format(dataAll.shape))\n",
    "print(\"Dimensões de dataAll: {}\".format(dataAll.ndim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Como havia 3000 exemplos anteriormente e agora a matriz tem dimensões (1, 3). \n",
    "Então, há 3000/3 = 1000 exemplos em dataAll. Ou seja, (1000, 1, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em x, y e rotulo \n",
    "\n",
    "print(\"x:\")\n",
    "x = dataAll[:, :, :2]\n",
    "print(x.shape)\n",
    "print(x[:10]) # Mostrando os 10 primeiros pontos \n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"y:\")\n",
    "y = dataAll[:,:, 2:]\n",
    "print(y.shape)\n",
    "print(y[:10]) # Rótulos dos pontos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Criando o neurônio Perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \"\"\"\n",
    "    A perceptron is a classification model that consists of a set of weights, or scores,\n",
    "    one for every feature, and a threshold. The perceptron multiplies each weight by its\n",
    "    corresponding score, and adds them, obtaining a score.\n",
    "    by Rajwrite Nath on Medium\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, threshold, lr, weight_low=-0.5, weight_high=0.5):\n",
    "        self.threshold = threshold\n",
    "        self.lr = lr\n",
    "        self.weights = None\n",
    "        self.weight_low = weight_low\n",
    "        self.weight_high = weight_high\n",
    "        self.scores = None\n",
    "        self.adjustments = 0\n",
    "        self.epochs = 0\n",
    "        self.bias = -1\n",
    "\n",
    "    def print_weights(self):\n",
    "        np.set_printoptions()\n",
    "        print(\"Weights:{}\".format(self.weights))\n",
    "\n",
    "    def gen_weights(self, low, high, size):\n",
    "        self.weights = np.random.uniform(low, high, size=size).reshape(-1, 1)\n",
    "\n",
    "    def step_fn(self, z):\n",
    "        return np.where(z >= self.threshold, 1, 0)\n",
    "\n",
    "    def error_fn(self, y_true, y_predicted):\n",
    "        return y_true - y_predicted\n",
    "\n",
    "    def predict(self, x_data):\n",
    "        return self.step_fn(np.dot(x_data, self.weights))\n",
    "\n",
    "    def fit(self, x_data, y_data):\n",
    "        \n",
    "        # Adicionando um bias ao x_data:\n",
    "        bias = np.full((x_data.shape[0], 1, 1), self.bias)\n",
    "        x_data = np.concatenate([bias, x_data], axis=2)\n",
    "        # print(x_data)\n",
    "        # print(x_data.shape)\n",
    "        \n",
    "        # Gerando pesos\n",
    "        self.gen_weights(self.weight_low, self.weight_high, size=x_data.shape[2])\n",
    "        # print(\"Início:\")\n",
    "        # self.print_weights()\n",
    "        # print(self.weights.shape)\n",
    "        \n",
    "        \n",
    "        y_predicted = self.predict(x_data)\n",
    "        self.scores = y_predicted  # Atualiza os scores\n",
    "\n",
    "        # Algoritmo executa até a convergência, supomos que as classes sejam linearmente separáveis\n",
    "        while not np.all(y_data == self.scores):\n",
    "\n",
    "            self.epochs += 1  # Não convergiu, vai necessitar de mais 1 época\n",
    "\n",
    "            # Para os pesos que resultaram em uma predição errada:\n",
    "\n",
    "            predicoes_incorretas = np.where(y_data != self.scores)[0]\n",
    "\n",
    "            for i in predicoes_incorretas:\n",
    "                x_i = x_data[i]\n",
    "                y_i = y_data[i]\n",
    "                y_pred = y_predicted[i]\n",
    "\n",
    "                # Calculando erros\n",
    "                error = self.error_fn(y_i, y_pred)\n",
    "\n",
    "                # Relculando pesos\n",
    "                self.weights += self.lr * error * x_i.T\n",
    "                self.adjustments += 1\n",
    "\n",
    "            y_predicted = self.predict(x_data)\n",
    "            self.scores = y_predicted # Atualiza os scores novamente com base nos ajustes\n",
    "\n",
    "# Inicializando o neurônio\n",
    "neuronio_perceptron = Perceptron(threshold=0, lr=0.1)\n",
    "neuronio_perceptron.fit(x, y)\n",
    "print(\"Final: \")\n",
    "neuronio_perceptron.print_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando o gráfico\n",
    "\n",
    "def gen_grafico(data, final_w, title):\n",
    "    x_1 = data[:,:, :1]\n",
    "    x_2 = data[:,:, 1:2]\n",
    "    y = data[:, :, 2:]\n",
    "    fig, ax = plt.subplots()\n",
    "    cor = {0: 'red', 1:'blue'}\n",
    "    for i in range(data.shape[0]):\n",
    "        plt.plot(x_1[i][0][0], x_2[i][0][0], marker='o', c = cor[y[i][0][0]])\n",
    "        \n",
    "    \n",
    "    x = np.arange(-1000, 1001, 1)\n",
    "    reta = (final_w[0][0]/final_w[2][0]) - (final_w[1][0]/final_w[2][0]) * x\n",
    "    plt.plot(x, reta, color='purple', linestyle='--', markersize=0.5)\n",
    "    ax.legend(cor, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax.grid(True)\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "gen_grafico(dataAll, neuronio_perceptron.weights, \"Distribução dos exemplos em dataAll\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Parte II - Experimentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "arq1 = \"data1.txt\"\n",
    "\n",
    "data1 = np.fromfile(arq1, dtype=np.float64)\n",
    "\n",
    "print(\"Tipo de data1: {}\".format(type(data1)))\n",
    "print(\"Número de elementos em data1: {}\".format(data1.size))\n",
    "print(\"\\n\")\n",
    "\n",
    "data1 = np.reshape(data1, (600, 1, 3))\n",
    "print(data1[:10])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Shape de data1: {}\".format(data1.shape))\n",
    "print(\"Dimensões de data1: {}\".format(data1.ndim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em x, y e rotulo \n",
    "\n",
    "print(\"x:\")\n",
    "x = data1[:, :, :2]\n",
    "print(x.shape)\n",
    "print(x[:10]) # Mostrando os 10 primeiros pontos \n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"y:\")\n",
    "y = data1[:,:, 2:]\n",
    "print(y.shape)\n",
    "print(y[:10]) # Rótulos dos pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [(0.4, (-100, 100)),\n",
    "         (0.1, (-100, 100)),\n",
    "         (0.01, (-100, 100)),\n",
    "         (0.4, (-0.5, 0.5)),\n",
    "         (0.1, (-0.5, 0.5)),\n",
    "         (0.01, (-0.5, 0.5))] # as seis configurações do \n",
    "\n",
    "def run_experiment(x, y, config, n_runs=10):\n",
    "    results = []\n",
    "    \n",
    "    for lr, (weight_low, weight_high) in config:\n",
    "        adjustments = []\n",
    "        epochs = []\n",
    "        \n",
    "        for _ in range (n_runs):\n",
    "            p = Perceptron(threshold=0, lr=lr, weight_low=weight_low, weight_high=weight_high)\n",
    "            p.fit(x, y)\n",
    "            adjustments.append(p.adjustments)\n",
    "            epochs.append(p.epochs)\n",
    "            \n",
    "        media_ajustes = np.mean(adjustments)\n",
    "        desvio_ajustes = np.std(adjustments)\n",
    "        menor_epoca = np.min(epochs)\n",
    "\n",
    "        results.append((lr, (weight_low, weight_high), media_ajustes, desvio_ajustes, menor_epoca))\n",
    "    \n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_table(results):\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Taxa de Aprendizado\", \"Intervalo de Pesos\", \"Quantidade de ajustes\", \"Menor número de épocas para convergência\"]\n",
    "\n",
    "    for lr, (w_low, w_high), media, desvio, min_epocas in results:\n",
    "        ajustes_fmt = f\"{media:.2f} ± {desvio:.2f}\"\n",
    "        intervalo_fmt = f\"({w_low}, {w_high})\"\n",
    "        table.add_row([lr, intervalo_fmt, ajustes_fmt, min_epocas])\n",
    "\n",
    "    print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_experiment(x, y, config, n_runs=10)\n",
    "print_results_table(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Taxas de aprendizado altas (0.1-0.4) aceleram a convergência (3-15 épocas) mas causam instabilidade, especialmente com pesos iniciais amplos (-100 a 100). Taxas baixas (0.01) são estáveis porém lentas (5-40 épocas), exceto quando combinadas com pesos em escala reduzida (-0.5 a 0.5), que otimizam o treinamento (1.400 ajustes em 5 épocas). A melhor configuração equilibrada é taxa 0.1 com pesos entre -0.5 e 0.5, garantindo convergência rápida (6 épocas) e estável. A escolha da inicialização e taxa de aprendizado é decisiva para um treinamento eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Parte III – Validação Holdout em Problema Não-Linearmente Separável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "arq_holdout = \"dataHoldout.txt\"\n",
    "\n",
    "dataHoldout = np.fromfile(arq_holdout, dtype=np.float64)\n",
    "\n",
    "print(\"Tipo de dataHoldout: {}\".format(type(dataHoldout)))\n",
    "print(\"Número de elementos em dataHoldout: {}\".format(dataHoldout.size))\n",
    "print(\"\\n\")\n",
    "\n",
    "dataHoldout = np.reshape(dataHoldout, (800, 1, 3))\n",
    "print(dataHoldout[:10])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Shape de dataHoldout: {}\".format(dataHoldout.shape))\n",
    "print(\"Dimensões de dataHoldout: {}\".format(dataHoldout.ndim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_grafico(data,title):\n",
    "    x_1 = data[:,:, :1]\n",
    "    x_2 = data[:,:, 1:2]\n",
    "    y = data[:, :, 2:]\n",
    "    fig, ax = plt.subplots()\n",
    "    cor = { 0: 'red', 1:'blue'}\n",
    "    for i in range(data.shape[0]):\n",
    "        plt.plot(x_1[i][0][0], x_2[i][0][0], marker='o', c = cor[y[i][0][0]])\n",
    "    \n",
    "    ax.legend(cor, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "        \n",
    "holdout_grafico(dataHoldout,\"Gráfico Inicial de Espalhamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declarando a semente de aleatoriedade\n",
    "np.random.seed(1)\n",
    "\n",
    "#Utilização do permutation para embaralhar a array dataHoldout\n",
    "np.random.permutation(dataHoldout)\n",
    "\n",
    "#Definição do tamanho do array de treino como 70% do original\n",
    "training_amount=int(800*0.7)\n",
    "\n",
    "#Divisão de teste e treino\n",
    "training_sample=dataHoldout[:(training_amount)]\n",
    "test_sample=dataHoldout[(training_amount):]\n",
    "\n",
    "#Análise se as amostras se mantém constantes \n",
    "print(training_sample[:10])\n",
    "print(\"\\n\")\n",
    "print(test_sample[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em x, y e rotulo de teste e treino\n",
    "\n",
    "print(\"x_Treino:\")\n",
    "x_training= training_sample[:, :, :2]\n",
    "print(x_training.shape)\n",
    "print(x_training[:5]) # Mostrando os 5 primeiros pontos \n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"y_training:\")\n",
    "y_training = training_sample[:,:, 2:]\n",
    "print(y_training.shape)\n",
    "print(y_training[:5]) # Rótulos dos pontos\n",
    "\n",
    "\n",
    "print(\"x_Teste:\")\n",
    "x_test= test_sample[:, :, :2]\n",
    "print(x_test.shape)\n",
    "print(x_test[:5]) # Mostrando os 5 primeiros pontos \n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"y_test:\")\n",
    "y_test = test_sample[:,:, 2:]\n",
    "print(y_test.shape)\n",
    "print(y_test[:5]) # Rótulos dos pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controled_Perceptron:\n",
    "    \"\"\"\n",
    "    This class works equals to the Perceptron class, but it doesn't stop when the neuron is all trained but when a\n",
    "    limit of epochs has been passed\n",
    " \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, threshold, lr ,limit):\n",
    "        self.threshold = threshold\n",
    "        self.lr = lr\n",
    "        self.weights = None\n",
    "        self.scores = None\n",
    "        self.adjustments = 0\n",
    "        self.epochs = 0\n",
    "        self.bias = -1\n",
    "        self.limit=limit\n",
    "\n",
    "    def print_weights(self):\n",
    "        np.set_printoptions()\n",
    "        print(\"Weights:{}\".format(self.weights))\n",
    "\n",
    "    def gen_weights(self, low, high, size):\n",
    "        self.weights = np.random.uniform(low, high, size=size).reshape(-1, 1)\n",
    "\n",
    "    def step_fn(self, z):\n",
    "        return np.where(z >= self.threshold, 1, 0)\n",
    "\n",
    "    def error_fn(self, y_true, y_predicted):\n",
    "        return y_true - y_predicted\n",
    "\n",
    "    def predict(self, x_data):\n",
    "        return self.step_fn(np.dot(x_data, self.weights))\n",
    "\n",
    "    def fit(self, x_data, y_data):\n",
    "        \n",
    "        # Adicionando um bias ao x_data:\n",
    "        bias = np.full((x_data.shape[0], 1, 1), self.bias)\n",
    "        x_data = np.concatenate([bias, x_data], axis=2)\n",
    "        print(x_data)\n",
    "        print(x_data.shape)\n",
    "        \n",
    "        # Gerando pesos\n",
    "        self.gen_weights(-0.5, 0.5, size=x_data.shape[2])\n",
    "        print(\"Início:\")\n",
    "        self.print_weights()\n",
    "        print(self.weights.shape)\n",
    "        \n",
    "        \n",
    "        y_predicted = self.predict(x_data)\n",
    "        self.scores = y_predicted  # Atualiza os scores\n",
    "\n",
    "        # Algoritmo executa até a convergência, supomos que as classes sejam linearmente separáveis\n",
    "        while(self.epochs<=self.limit):\n",
    "\n",
    "            self.epochs += 1  # Não convergiu, vai necessitar de mais 1 época\n",
    "\n",
    "            # Para os pesos que resultaram em uma predição errada:\n",
    "\n",
    "            predicoes_incorretas = np.where(y_data != self.scores)[0]\n",
    "\n",
    "            for i in predicoes_incorretas:\n",
    "                x_i = x_data[i]\n",
    "                y_i = y_data[i]\n",
    "                y_pred = y_predicted[i]\n",
    "\n",
    "                # Calculando erros\n",
    "                error = self.error_fn(y_i, y_pred)\n",
    "\n",
    "                # Relculando pesos\n",
    "                self.weights += self.lr * error * x_i.T\n",
    "                self.adjustments += 1\n",
    "\n",
    "            y_predicted = self.predict(x_data)\n",
    "            self.scores = y_predicted # Atualiza os scores novamente com base nos ajustes\n",
    "            \n",
    "neuronio_perceptron_holdout = Controled_Perceptron(threshold=0, lr=0.1, limit=100)\n",
    "neuronio_perceptron_holdout.fit(x_training, y_training)\n",
    "print(\"Final: \")\n",
    "neuronio_perceptron_holdout.print_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_line_grafico(data,final_w,title):\n",
    "    x_1 = data[:,:, :1]\n",
    "    x_2 = data[:,:, 1:2]\n",
    "    y = data[:, :, 2:]\n",
    "    fig, ax = plt.subplots()\n",
    "    cor = { 0: 'red', 1:'blue'}\n",
    "    for i in range(data.shape[0]):\n",
    "        plt.plot(x_1[i][0][0], x_2[i][0][0], marker='o', c = cor[y[i][0][0]])\n",
    "        \n",
    "    x = np.arange(-1, 3, 1)\n",
    "    reta = (final_w[0][0]/final_w[2][0]) - (final_w[1][0]/final_w[2][0]) * x\n",
    "    plt.plot(x, reta, color='purple', linestyle='--', markersize=0.5)\n",
    "    \n",
    "    ax.legend(cor, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "        \n",
    "holdout_line_grafico(dataHoldout,neuronio_perceptron_holdout.weights,\"Distruibuição de exemplos de dataHoldout\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
